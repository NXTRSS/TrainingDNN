{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EcAhN7p55_t-",
    "outputId": "fbd5ee4c-8da0-40f2-a7cc-a1283401c607",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcje pomocnicze\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdrX9lpR5_ug"
   },
   "source": [
    "# Pierwszy przykład sieci neuronowej\n",
    "\n",
    "Nie przejmuj się, jeżeli nie zrozumiesz wszystkich elementów tego przykładu. Jest to normalne, jeżeli nie masz doświadczenia w pracy z biblioteką Keras ani innym podobnym do niej pakietem. W związku z tym nie przejmuj się, jeżeli niektóre rzeczy wydadzą Ci się czarną magią! Musimy od czegoś zacząć.\n",
    "\n",
    "W zaprezentowanym przykładzie próbujemy rozwiązać problem klasyfikacji obrazów w skali szarości przedstawiających ręcznie zapisane cyfry (obrazy te mają rozdzielczość 28x28 pikseli). Chcemy podzielić je na 10 kategorii (cyfry od 0 do 9). Będziemy korzystać ze zbioru danych MNIST, który jest uznawany przez środowisko analityków za zbiór klasyczny. Istnieje on tak długo, jak długa jest historia uczenia maszynowego. Zbiór ten zawiera 60 000 obrazów treningowych oraz 10 000 obrazów testowych. Został on utworzony przez Narodowy Instytut Standaryzacji i Technologii (NIST) w latach 80. ubiegłego wieku. Rozwiązanie wspomnianego problemu można porównać do wyświetlenia napisu „Witaj, świecie!” podczas nauki nowego języka programowania. Zbiór ten jest również używany w celu sprawdzania tego, czy algorytm działa poprawnie. Jeżeli zaczniesz zawodowo zajmować się uczeniem maszynowym, to odkryjesz, że zbiór MNIST pojawia się ciągle w różnych pracach naukowych, artykułach publikowanych w internecie itd. Poniżej pokażemy kilka obrazów z tego zbioru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vj-fqx35_un"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# Sformatowano jako kod\n",
    "```\n",
    "\n",
    "Zbiór danych MNIST jest dołączony do pakietu Keras w formie czterech tablic Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RYWa3HT5_up",
    "outputId": "6125d070-7a42-4b1d-c0bc-077fd0c0eca4"
   },
   "outputs": [],
   "source": [
    "#ściągnięcie danych\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWhxg1GH5_ur"
   },
   "source": [
    "Tablice train_images i train_labels tworzą treningowy zbiór danych. Będzie on używany podczas trenowania modelu. Do testowania posłuży nam testowy zbiór danych, składający się z tablic test_images i test_labels. Obrazy są zakodowane w formie tablic Numpy, a etykiety mają formę tablicy cyfr (od 0 do 9). Do każdego obrazu przypisana jest tylko jedna etykieta.\n",
    "\n",
    "Przyjrzyjmy się treningowemu zbiorowi danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zobaczmy losowo kilka obrazków ze zbioru testowego\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "idxs = random.sample(range(len(test_images)), len(axes))\n",
    "\n",
    "for idx, axis in zip(idxs, axes):\n",
    "    first_image = test_images[idx]\n",
    "    first_image = np.array(first_image, dtype='float')\n",
    "    pixels = first_image.reshape((28, 28))\n",
    "    axis.set_axis_off() \n",
    "    axis.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lu2e-E_5_uu",
    "outputId": "c4529c5a-d1d1-49a3-91f3-97ba4160788d"
   },
   "outputs": [],
   "source": [
    "#sprawdźmy rozmiar treningowej macierzy obrazków\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9wlYG0Y5_uv",
    "outputId": "5b1b7e6c-60e5-4e9d-f696-4641dd478cd1"
   },
   "outputs": [],
   "source": [
    "#sprawdźmy liczbę próbek w zbiorze treningowym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K91yePNi5_ux",
    "outputId": "6772b51e-0aba-4c49-c57a-8307320df148"
   },
   "outputs": [],
   "source": [
    "#zobaczmy jak wyglądają klasy w zbiorze treningowym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zobaczmy unikalne klasy w zbiorze treningowym\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8narrhL5_u0"
   },
   "source": [
    "A teraz zobaczmy, jak wyglądają dane testowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I42mf8K-5_u2",
    "outputId": "b9719719-193d-4226-df95-711cb15f57cb"
   },
   "outputs": [],
   "source": [
    "#sprawdźmy rozmiar testowej macierzy obrazków\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nF96JbXs5_u4",
    "outputId": "49f87125-f01d-49af-c364-79c682d2c83c"
   },
   "outputs": [],
   "source": [
    "#sprawdźmy liczbę próbek w zbiorze testowym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QyowQccG5_u6",
    "outputId": "9f98f41a-a8d1-4f81-900e-514eb5ebed4b"
   },
   "outputs": [],
   "source": [
    "#zobaczmy unikalne klasy w zbiorze testowym\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uk-2ZK6U5_u7"
   },
   "source": [
    "Będziemy pracować według następującego przepływu roboczego: najpierw będziemy trenować sieć neuronową na danych treningowych: train_images i train_labels. Sieć nauczy się kojarzyć obrazy i etykiety. Następnie nasza sieć wygeneruje przewidywania dotyczące zbioru test_images, a uzyskane wyniki porównamy z etykietami test_labels.\n",
    "\n",
    "Zbudujmy naszą sieć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#proszę wygenerować sieć o 4 warstwach w kerasie:\n",
    "# - gęsta z 512 neuronami, funkcją aktywacji ReLU, odpowiednim rozmiarem wejścia\n",
    "# - dropout ze współczynnikiem odrzucenia 40%\n",
    "# - gęsta z 256 neuronami, funkcją aktywacji Tanh\n",
    "# - gęsta z licznością klas predykcji, funkcja aktywacji softmax\n",
    "\n",
    "network = models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXvMtL7r5_u-"
   },
   "source": [
    "Głównym blokiem składowym sieci neuronowej jest warstwa (ang. layer). Jest to moduł przetwarzania danych, który można traktować jako filtr danych. Dane wychodzące z filtra mają bardziej przydatną formę od danych do niego wchodzących. Niektóre warstwy dokonują ekstrakcji reprezentacji kierowanych do nich danych — reprezentacje te powinny ułatwiać rozwiązanie problemu, z którym się zmagamy. Większość uczenia głębokiego składa się z łączenia ze sobą prostych warstw w celu zaimplementowania progresywnej destylacji danych. Model uczenia głębokiego jest jak sito przetwarzające dane składające się z coraz drobniejszych siatek — warstw.\n",
    "\n",
    "Nasza sieć składa się z sekwencji dwóch warstw Dense, które są ze sobą połączone w sposób gęsty (dochodzi tu do gęstego połączenia). Druga warstwa jest dziesięcioelementową warstwą softmax — warstwa ta zwróci tablicę 10 wartości prawdopodobieństwa (suma wszystkich tych wartości jest równa 1). Każdy z tych wyników określa prawdopodobieństwo tego, że na danym obrazie przedstawiono daną cyfrę (obraz może przedstawiać jedną z dziesięciu cyfr).\n",
    "\n",
    "Na etapie kompilacji musimy określić jeszcze trzy rzeczy w celu przygotowania sieci do trenowania. Są to:\n",
    "\n",
    "* Funkcja straty — funkcja ta definiuje sposób pomiaru wydajności sieci podczas przetwarzania treningowego zbioru danych, a więc pozwala na dostrajanie parametrów sieci we właściwym kierunku.\n",
    "* Optymalizator — mechanizm dostrajania sieci na podstawie danych zwracanych przez funkcje straty.\n",
    "* Metryki monitorowane podczas trenowania i testowania — tutaj interesuje nas jedynie dokładność (część obrazów, która została właściwie sklasyfikowana)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5y2RYYE5_vA"
   },
   "outputs": [],
   "source": [
    "#proszę skompilować sieć z optimizerem Adam, funkcją kosztu categorical crossentropy i śledzonymi miarami:\n",
    "#'accuracy', f1_m, precision_m, recall_m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9-FrGg-5_vB"
   },
   "source": [
    "\n",
    "Zanim rozpoczniemy trenowanie, zmienimy kształt danych tak, aby przyjęły kształt oczekiwany przez sieć, i przeskalujemy je do wartości z zakresu [0, 1]. Początkowo nasze obrazy treningowe były zapisywane w postaci macierzy o wymiarach (60000, 28, 28), zawierającej wartości z zakresu [0, 255], i typie uint8. Przekształcamy je w tablicę typu float32 o wymiarach (60000, 28 * 28), zawierającą wartości od 0 do 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YaYMX5f5_vC"
   },
   "outputs": [],
   "source": [
    "# reshape danych treningowych (spłaszczanie obrazków)\n",
    "\n",
    "# normalizacja danych treningowych poprzez podzielenie przez maksymalną wartość\n",
    "\n",
    "\n",
    "# reshape danych testowych (spłaszczanie obrazków)\n",
    "\n",
    "# normalizacja danych testowych poprzez podzielenie przez maksymalną wartość\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_YhQunS5_vD"
   },
   "source": [
    "Musimy dodatkowo zakodować etykiety za pomocą kategorii, czyli zamiast wartości od 0 do 9 chcemy mieć wektory z samymi 0 i jedną 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMIoSC1U5_vE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# kategoryzacja klas danych treningowych\n",
    "\n",
    "\n",
    "# kategoryzacja klas danych testowych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDm7-fCN5_vG",
    "outputId": "4661ef28-8a1e-4c39-e676-b59d757b4ed1"
   },
   "outputs": [],
   "source": [
    "# uczenie utworzonej sieci, liczba epok:10, wielkość batcha: 128\n",
    "#proszę podać dane testowe jako validation_data w procesie uczenia\n",
    "#dla chętnych - proszę dodać callback, który stworzy logi dla Tensorboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jeśli utworzono logi za pomocą callback można odkomentować poniższą linijkę\n",
    "\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jeśli utworzono logi za pomocą callback można odkomentować poniższą linijkę\n",
    "\n",
    "# tensorboard --logdir=network_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqpdYbPa5_vI"
   },
   "source": [
    "Podczas trenowania szybko osiągamy dokładność około 0,98 (98%). Teraz możemy sprawdzić dokładność przetwarzania testowego zbioru danych:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGHu5FZq5_vK",
    "outputId": "4825894a-9ca4-4486-866d-0f240707d697"
   },
   "outputs": [],
   "source": [
    "# inferencja na zbiorze testowym - proszę zapisać wyniki\n",
    "test_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXvD7vO05_vM",
    "outputId": "931530af-78d7-4c6e-eafc-d418d30041bd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#proszę wypisać dokładność zbioru testowego (druga wartość z test_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06W1cwvB5_vN"
   },
   "source": [
    "\n",
    "W przypadku testowego zbioru danych również uzyskaliśmy dokładność na poziomie około 98%, zwykle niższą niż na zbiorze treningowym. Różnica między tymi wartościami wynika z nadmiernego dopasowania. Modele uczenia maszynowego mają tendencję do niższej dokładności przetwarzania nowych danych, niż to miało miejsce w przypadku danych treningowych. Zagadnienie to jest głównym tematem rozdziału 3.\n",
    "\n",
    "To tyle, jeżeli chodzi o nasz pierwszy przykład — właśnie zobaczyłeś, że zbudowanie i wytrenowanie sieci neuronowej klasyfikującej zapis ręczny cyfr może zająć mniej niż 20 linii kodu Pythona.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Training_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
