{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swHNn-yE6pVA"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJOEpnWc6pVH"
   },
   "source": [
    "# Nadmierne dopasowanie i zbyt słabe dopasowanie\n",
    "\n",
    "Zwykle przy zastosowaniu sieci neuronowych widzimy pewien wzorzec — wydajność modelu podczas przetwarzania odłożonego na bok walidacyjnego zbioru danych zawsze po kilku epokach osiągała wartość szczytową, a następnie ulegała degradacji — modele zaczynały ulegać nadmiernemu dopasowaniu do danych treningowych. Do nadmiernego dopasowania może dojść podczas pracy nad dowolnym problemem uczenia maszynowego. Pracując z algorytmami uczenia maszynowego, musimy wiedzieć, jak radzić sobie z tym problemem.\n",
    "\n",
    "Podstawowym problemem uczenia maszynowego jest kompromis między optymalizacją a uogólnianiem. Optymalizacja jest procesem dostrajania modelu w celu uzyskania najlepszej możliwej wydajności na danych treningowych (jest to proces uczenia, od którego wzięła się nazwa uczenie maszynowe), a uogólnianie (generalizacja) odwołuje się do tego, jak dobrze wytrenowany model sprawdza się podczas przetwarzania danych, których nigdy nie widział. Oczywiście chcemy uzyskać jak najlepszą zdolność modelu do uogólniania, ale nie mamy na to wpływu w sposób bezpośredni, ponieważ model możemy modyfikować tylko na danych treningowych.\n",
    "\n",
    "Na początku trenowania optymalizacja i uogólnianie są ze sobą skorelowane — im mniejsza strata na danych treningowych, tym mniejsza strata na danych testowych. Gdy taka sytuacja ma miejsce, mamy do czynienia ze zbyt słabym dopasowaniem — model może zostać lepiej dopasowany, ponieważ sieć nie dokonała jeszcze modelowania wszystkich wzorców znajdujących się w danych treningowych, ale po pewnej liczbie iteracji algorytmu przetwarzającego dane treningowe uogólnianie przestaje ulegać poprawie, a metryka walidacji przyjmuje wartość stałą lub pogarsza się — wówczas model zaczyna dopasowywać się nadmiernie, a więc zaczyna uczyć się wzorców, które są specyficzne dla danych treningowych i wprowadzają w błąd lub są nieprzydatne podczas przetwarzania nowych danych.\n",
    "\n",
    "Aby zapobiec uczeniu się przez model błędnych lub zbędnych wzorców treningowego zbioru danych, najlepiej jest zebrać więcej danych treningowych. To dość oczywiste, że model trenowany na większej liczbie obserwacji będzie zdolny do lepszego uogólniania. Jeśli takie rozwiązanie nie jest możliwe, możemy modulować ilość informacji, które model może przechowywać, lub dodać ograniczenia co do możliwości przechowywania informacji przez model. Jeżeli sieć może zapamiętać tylko niewielką liczbę wzorców, to proces optymalizacji wymusi skupienie się na najważniejszych wzorcach, które najprawdopodobniej lepiej sprawdzą się przy uogólnianiu.\n",
    "\n",
    "Proces walki z nadmiernym dopasowaniem określamy mianem regularyzacji. Chciałbym opisać najpopularniejsze techniki regularyzacji i zastosować je w praktyce w celu poprawy działania modelu klasyfikacji sentymentu (pozytywny / negatywny) na podstawie opinii o filmach z bazy imdb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyy_iVMN6pVN"
   },
   "source": [
    "Uwaga: W charakterze zbioru walidacyjnego będziemy korzystać ze zbioru testowego IMDB. W tym przypadku nie jest to żadnym problemem.\n",
    "\n",
    "Przygotujmy dane do analizy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdyTfzZ_6pVP"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "EPOCHS = 20\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Zbiór treningowy w postaci wektora.\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Zbiór testowy w postaci wektora.\n",
    "x_test = vectorize_sequences(test_data)\n",
    "# Etykiety w postaci wektorów.\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsgYcGMm6pVR"
   },
   "source": [
    "# Zmniejszanie nadmiernego dopasowania\n",
    "\n",
    "## Redukcja rozmiaru sieci\n",
    "\n",
    "\n",
    "Najprostszym sposobem zapobiegania powstawaniu nadmiernego dopasowania jest zmniejszenie rozmiaru modelu: zmniejszenie liczby uczonych parametrów, na którą wpływa liczba warstw i liczba jednostek je tworzących. W uczeniu głębokim uczone parametry modelu często określa się mianem pojemności modelu. Model dysponujący większą liczbą parametrów charakteryzuje się większą pojemnością pamięci, a więc może łatwiej uczyć się doskonałego mapowania danych przypominającego swym działaniem słownik. Mapowanie takie nie ma żadnej zdolności uogólniania. Przykładowy model z 500 000 parametrów binarnych mógłby z łatwością nauczyć się klasy każdej cyfry wchodzącej w skład treningowego zbioru danych MNIST: każda z 50 000 cyfr mogłaby zostać opisana przy użyciu zaledwie 10 parametrów binarnych, ale taki model byłby zupełnie nieprzydatny podczas klasyfikacji nowych próbek. Musisz pamiętać o tym, że modele uczenia głębokiego mają tendencję do dopasowywania się do danych treningowych, ale Twoim celem jest osiągnięcie modelu zdolnego do jak najlepszych uogólnień, a nie modelu maksymalnie dopasowanego do danych treningowych.\n",
    "\n",
    "Jeżeli sieć dysponuje zbyt małą zdolnością zapamiętywania, to nie będzie w stanie tak łatwo nauczyć się bezpośredniego mapowania, a więc w celu minimalizacji strat będzie musiała uczyć się skompresowanych reprezentacji, co pozwoli modelowi nabyć umiejętności przewidywania, a o to nam właśnie chodzi. Jednocześnie należy pamiętać o tym, że modele powinny mieć na tyle dużo parametrów, aby nie ulec zbyt słabemu dopasowaniu — model nie powinien cierpieć z powodu braku możliwości zapamiętywania kolejnych cech. Trzeba znaleźć kompromis między zbyt dużą pojemnością a zbyt małą pojemnością.\n",
    "\n",
    "Niestety nie ma żadnego magicznego wzoru umożliwiającego określenie właściwej liczby warstw i odpowiednich rozmiarów poszczególnych warstw. W celu znalezienia modelu optymalnego z punktu widzenia analizowanych danych należy sprawdzić działanie zestawu różnych architektur (oczywiście trzeba to robić na zbiorze walidacyjnym, a nie testowym). Szukanie odpowiedniego modelu należy zacząć od niewielkiej liczby warstw i parametrów, a następnie zwiększać rozmiary istniejących warstw i stopniowo dodawać nowe, obserwując spadek wartości straty określanej w procesie walidacji.\n",
    "\n",
    "Spróbujmy zastosować to rozwiązanie w kontekście sieci klasyfikującej recenzje filmów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e69zjDyG6pVU"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#proszę wygenerować sieć o 3 warstwach w kerasie:\n",
    "# - gęsta z 16 neuronami, funkcją aktywacji ReLU, odpowiednim rozmiarem wejścia\n",
    "# - gęsta z 16 neuronami, funkcją aktywacji ReLU\n",
    "# - gęsta z 1 neuronem wyjściowym, funkcja aktywacji sigmoid\n",
    "\n",
    "benchmark_model = models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9jfiCAv-CYh"
   },
   "outputs": [],
   "source": [
    "benchmark_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhV-NiOC-CYi"
   },
   "outputs": [],
   "source": [
    "#proszę skompilować model, optimizer RMSprop, funkcja kosztu binary crossentropy i śledzoną miarą accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTk07iv06pVY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#proszę wytrenować powyższy model, liczba epok: EPOCHS, rozmiar batcha: 512, \n",
    "#proszę podać dane testowe jako validation_data w procesie uczenia\n",
    "benchmark_hist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, EPOCHS+1)\n",
    "benchmark_val_loss = benchmark_hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDPNVhqD6pVV"
   },
   "source": [
    "Spróbujmy zastąpić ten model prostszą siecią neuronową:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USEHBIF56pVW"
   },
   "outputs": [],
   "source": [
    "#proszę wygenerować sieć o 3 warstwach w kerasie z mniejszą liczbą parametrów:\n",
    "# - gęsta z 4 neuronami, funkcją aktywacji ReLU, odpowiednim rozmiarem wejścia\n",
    "# - gęsta z 4 neuronami, funkcją aktywacji ReLU\n",
    "# - gęsta z 1 neuronem wyjściowym, funkcja aktywacji sigmoid\n",
    "smaller_model = models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnOZs7gO-CYj"
   },
   "outputs": [],
   "source": [
    "smaller_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMGATXFN-CYj"
   },
   "outputs": [],
   "source": [
    "#proszę skompilować model, optimizer RMSprop, funkcja kosztu binary crossentropy i śledzoną miarą accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aoLajOS6pVX"
   },
   "source": [
    "\n",
    "Oto porównanie straty walidacji oryginalnej sieci i mniejszej sieci. Kropkami oznaczono wartości straty walidacji mniejszej sieci, a krzyżykami oznaczono wartości straty oryginalnej sieci (przypominam, że mniejsza wartość straty walidacji świadczy o tym, że model jest lepszy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gz0uyMS6pVa"
   },
   "outputs": [],
   "source": [
    "#proszę wytrenować powyższy model, liczba epok: EPOCHS, rozmiar batcha: 512, \n",
    "#proszę podać dane testowe jako validation_data w procesie uczenia\n",
    "smaller_model_hist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLOTKlhR6pVc"
   },
   "outputs": [],
   "source": [
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5vIEzAr6pVe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# b+ to niebieskie krzyżyki\n",
    "plt.plot(epochs, benchmark_val_loss, 'b+', label='Bazowy model')\n",
    "# bo to niebieskie kropki\n",
    "plt.plot(epochs, smaller_model_val_loss, 'bo', label='Mniejszy model')\n",
    "plt.xlabel('Epoki')\n",
    "plt.ylabel('Strata walidacji')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCY1TMos6pVg"
   },
   "source": [
    "\n",
    "Jak widać, mniejsza sieć zaczęła ulegać nadmiernemu dopasowaniu (przeuczeniu) później niż nasz początkowy model (po sześciu, a nie po czterech epokach), a dodatkowo po przekroczeniu punktu przeuczenia wydajność mniejszego modelu ulega wolniejszej degradacji.\n",
    "\n",
    "Spróbujmy przeanalizować w tym kontekście działanie sieci o znacznie większej pojemności (przekraczającej potrzeby problemu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLI3dmHl6pVh"
   },
   "outputs": [],
   "source": [
    "#proszę wygenerować sieć o 3 warstwach w kerasie z większą liczbą parametrów:\n",
    "# - gęsta z 512 neuronami, funkcją aktywacji ReLU, odpowiednim rozmiarem wejścia\n",
    "# - gęsta z 512 neuronami, funkcją aktywacji ReLU\n",
    "# - gęsta z 1 neuronem wyjściowym, funkcja aktywacji sigmoid\n",
    "bigger_model = models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5hHjhcl-CYl"
   },
   "outputs": [],
   "source": [
    "bigger_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d7fOkl6-CYl"
   },
   "outputs": [],
   "source": [
    "#proszę skompilować model, optimizer RMSprop, funkcja kosztu binary crossentropy i śledzoną miarą accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7cCZnbt6pVj"
   },
   "outputs": [],
   "source": [
    "#proszę wytrenować powyższy model, liczba epok: EPOCHS, rozmiar batcha: 512, \n",
    "#proszę podać dane testowe jako validation_data w procesie uczenia\n",
    "bigger_model_hist = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYD-S41o6pVl"
   },
   "source": [
    "Oto rysnek, na którym porównano wydajność zbyt dużej sieci i naszego początkowego modelu. Kropkami oznaczono stratę walidacji większej sieci, a krzyżykami oznaczono stratę walidacji początkowej wersji sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmkqo28u6pVm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bigger_model_val_loss = bigger_model_hist.history['val_loss']\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(epochs, benchmark_val_loss, 'b+', label='Bazowy model')\n",
    "axes[0].plot(epochs, bigger_model_val_loss, 'bo', label='Wiekszy model')\n",
    "axes[0].set_xlabel('Epoki')\n",
    "axes[0].set_ylabel('Strata walidacji')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(epochs, benchmark_val_loss, 'b+', label='Bazowy model')\n",
    "axes[1].plot(epochs, smaller_model_val_loss, 'bo', label='Mniejszy model')\n",
    "axes[1].set_xlabel('Epoki')\n",
    "axes[1].set_ylabel('Strata walidacji')\n",
    "axes[1].legend()\n",
    "\n",
    "ylim = (0, max(axes[0].get_ylim()[1], axes[1].get_ylim()[1]))\n",
    "axes[0].set_ylim(ylim)\n",
    "axes[1].set_ylim(ylim)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85UIy3sp6pVq"
   },
   "source": [
    "\n",
    "porównano wydajność zbyt dużej sieci i naszego początkowego modelu. Kropkami oznaczono stratę walidacji większej sieci, a krzyżykami oznaczono stratę walidacji początkowej wersji sieci.\n",
    "\n",
    "Oto rysunek, na którym porównano straty procesu trenowania dwóch sieci.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqLbAIfo6pVr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "benchmark_train_loss = benchmark_hist.history['loss']\n",
    "smaller_model_train_loss = smaller_model_hist.history['loss']\n",
    "bigger_model_train_loss = bigger_model_hist.history['loss']\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(epochs, benchmark_train_loss, 'b+', label='Bazowy model')\n",
    "axes[0].plot(epochs, bigger_model_train_loss, 'bo', label='Wiekszy model')\n",
    "axes[0].set_xlabel('Epoki')\n",
    "axes[0].set_ylabel('Strata treningowa')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(epochs, benchmark_train_loss, 'b+', label='Bazowy model')\n",
    "axes[1].plot(epochs, smaller_model_train_loss, 'bo', label='Mniejszy model')\n",
    "axes[1].set_xlabel('Epoki')\n",
    "axes[1].set_ylabel('Strata treningowa')\n",
    "axes[1].legend()\n",
    "\n",
    "ylim = (0, max(axes[0].get_ylim()[1], axes[1].get_ylim()[1]))\n",
    "axes[0].set_ylim(ylim)\n",
    "axes[1].set_ylim(ylim)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TA4CXLgj-CYn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2IRsvdy6pVu"
   },
   "source": [
    "Widać, że większa sieć bardzo szybko uzyskuje praktycznie zerową wartość straty treningowej. Im większa jest pojemność sieci, tym szybciej modelowane są dane treningowe (uzyskiwana jest niska wartość straty treningowej), ale wzrasta wówczas podatność na nadmierne dopasowanie (powstaje duża różnica między stratą treningową a stratą walidacji)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ellzReE6pVx"
   },
   "source": [
    "## Dodawanie regularyzacji wag\n",
    "\n",
    "\n",
    "Czy znasz zasadę brzytwy Ockhama? Według niej, jeżeli istnieją dwa wyjaśnienia jakiejś teorii, to najprawdopodobniej poprawnym wyjaśnieniem jest to, które jest prostsze — to, które czyni mniej założeń. Zasada ta sprawdza się również w kontekście modeli sieci neuronowych: jeżeli mamy dane treningowe, architekturę sieci i wiele zbiorów wartości wag (wiele modeli) opisujących dane, to prostsze modele są mniej podatne na nadmierne dopasowanie od tych, które są bardziej złożone.\n",
    "\n",
    "Przyjmijmy, że za prostszy model uważamy model, którego rozkład wartości parametrów charakteryzuje się mniejsza entropią, lub model, który ma mniej parametrów. W związku z tym popularną techniką unikania nadmiernego dopasowania jest wymuszenie na modelu ograniczenia złożoności poprzez przyjmowanie tylko małych wartości wag, co sprawia, że rozkład wartości wag jest bardziej regularny. Zabieg ten określamy mianem regularyzacji wag. Implementuje się go poprzez dodanie do funkcji straty sieci kosztu związanego z dużymi wartościami wag. W praktyce można to zrobić na dwa sposoby:\n",
    "\n",
    "\n",
    "* Regularyzacja L1 — koszt jest dodawany proporcjonalnie do bezwzględnej wartości współczynników wag (normy L1 wag).\n",
    "\n",
    "* Regularyzacja L2 — koszt jest dodawany proporcjonalnie do kwadratu wartości współczynników wag (normy L2 wag). W kontekście sieci neuronowych regularyzacja L2 jest również określana mianem rozkładu wag. Pomimo innej nazwy jest to ten sam proces, który w matematyce określamy jako regularyzacja L2.\n",
    "\n",
    "W pakiecie Keras regularyzację wag dodaje się poprzez przekazanie instancji regularyzatora wagi do warstw sieci za pomocą argumentu w formie słowa kluczowego. Dodajmy regularyzację L2 wag do sieci klasyfikatora recenzji filmów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxoR0g8f6pV0"
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "#proszę wygenerować sieć o 3 warstwach w kerasie z regularyzacją L2:\n",
    "# - gęsta z 16 neuronami, funkcją aktywacji ReLU, odpowiednim rozmiarem wejścia, regularyzacją L2 z argumentem 0.001\n",
    "# - gęsta z 16 neuronami, funkcją aktywacji ReLU, regularyzacją L2 z argumentem 0.001\n",
    "# - gęsta z 1 neuronem wyjściowym, funkcja aktywacji sigmoid\n",
    "l2_model = models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDokDeUO-CYn"
   },
   "outputs": [],
   "source": [
    "l2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31RBxTw86pV1"
   },
   "outputs": [],
   "source": [
    "#proszę skompilować model, optimizer RMSprop, funkcja kosztu binary crossentropy i śledzoną miarą accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3xX8XM36pV2"
   },
   "source": [
    "Argument l2(0.001) oznacza, że każdy współczynnik macierzy wag warstwy doda wartość równą 0.001 * weight_coefficient_value (0,001 razy wartość współczynnika wagi) do całkowitej straty sieci. Kara ta jest dodawana tylko podczas trenowania, a więc strata sieci w czasie trenowania będzie o wiele wyższa niż w czasie testowania.\n",
    "\n",
    "Oto wykres, na którym pokazano wpływ kary w postaci regularyzacji L2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZpNNizcz6pV3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#proszę wytrenować powyższy model, liczba epok: EPOCHS, rozmiar batcha: 512, \n",
    "#proszę podać dane testowe jako validation_data w procesie uczenia\n",
    "l2_model_hist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lO0JoiRX6pV4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, benchmark_val_loss, 'b+', label='Bazowy model')\n",
    "plt.plot(epochs, l2_model_val_loss, 'bo', label='Model z regularyzacja L2')\n",
    "plt.xlabel('Epoki')\n",
    "plt.ylabel('Strata walidacji')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQsoEp9o6pV5"
   },
   "source": [
    "\n",
    "\n",
    "Jak widać, model z regularyzacją L2 (kropki) stał się o wiele bardziej odporny na nadmierne dopasowanie od modelu referencyjnego (krzyżyki) pomimo tego, że oba modele charakteryzują się identyczną liczbą parametrów.\n",
    "\n",
    "Zamiast regularyzacji L2 możesz korzystać również z innych mechanizmów regularyzacji obsługiwanych przez pakiet Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQq-WU7i6pV6"
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "# Regularyzacja L1.\n",
    "regularizers.l1(0.001)\n",
    "\n",
    "# Jednoczesna regularyzacja L1 i L2.\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gZHoIsn6pV7"
   },
   "source": [
    "## Porzucanie — technika dropout\n",
    "\n",
    "\n",
    "Porzucanie (ang. droput) jest jedną z najbardziej skutecznych i najpopularniejszych technik regularyzacji sieci neuronowych. Opracował ją Geoffrey Hinton podczas współpracy ze swoimi studentami na Uniwersytecie w Toronto. Technika ta polega na losowym wybieraniu pewnej liczby cech wyjściowych warstwy podczas trenowania (wartości tych warstw są zastępowane zerami). Załóżmy, że w czasie trenowania warstwa sieci normalnie zwraca wektor \n",
    ">[0.2, 0.5, 1.3, 0.8, 1.1]\n",
    "\n",
    "Po przeprowadzeniu operacji porzucania w wektorze tym (w losowo wybranych miejscach) pojawią się zera i uzyska on np. formę \n",
    ">[0, 0.5, 1.3, 0, 1.1]\n",
    "\n",
    "Ułamek określający część wyzerowanych cech nazywamy współczynnikiem porzucania (ang. dropout rate). Zwykle parametr ten przyjmuje wartość znajdującą się w przedziale od 0,2 do 0,5. Podczas testowania żadne jednostki nie są porzucane — wartości wyjściowe warstwy sieci są skalowane o współczynnik równy (1 - $\\alpha$), gdzie $\\alpha$ to współczynnik porzucania. Równoważy to aktywność większej liczby jednostek podczas testowania niż trenowania.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6UrTNQs6pWB"
   },
   "source": [
    "\n",
    "Technika ta może wydawać się dziwna i chaotyczna. Jak ma pomóc w zmniejszeniu nadmiernego dopasowania? Hinton tworząc ją, inspirował się mechanizmami zapobiegającymi nadużyciom stosowanym przez banki. Stwierdził: „Pewnego dnia, gdy poszedłem do banku, zauważyłem, że osoby w okienkach często zmieniają swoje miejsca; pracownicy banku nie potrafili powiedzieć, dlaczego to robią, ale doszedłem do wniosku, że przy takiej rotacji wyłudzenie pieniędzy z banku wymagałoby współpracy wielu pracowników; wówczas zdałem sobie sprawę, że losowe usuwanie różnych podzbiorów neuronów podczas przetwarzania każdego przykładu zapobiegnie konspiracji i zredukuje nadmierne dopasowanie”. Główną ideą tej techniki jest wprowadzenie szumu do wartości wyjściowych warstwy w celu pozbycia się nieznaczących wzorców (Hinton określił je mianem „konspiracji”) — wprowadzenie szumu zapobiega zapamiętywaniu takich wzorców przez sieć.\n",
    "\n",
    "W pakiecie Keras technikę tę można zastosować przy użyciu warstwy Dropout, którą umieszcza się bezpośrednio za wyjściem znajdującej się wcześniej warstwy:\n",
    "```bash\n",
    "model.add(layers.Dropout(0.5))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v-991Us6pWC"
   },
   "source": [
    "Dodajmy dwie warstwy Dropout do sieci IMDB i zobaczmy, czy pomogą one w zredukowaniu nadmiernego dopasowania:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUMs9d8j6pWD"
   },
   "outputs": [],
   "source": [
    "#proszę wygenerować sieć o 5 warstwach w kerasie z regularyzacją L2:\n",
    "# - gęsta z 16 neuronami, funkcją aktywacji ReLU, odpowiednim rozmiarem wejścia\n",
    "# - dropout ze współczynnikiem odrzucenia 50%\n",
    "# - gęsta z 16 neuronami, funkcją aktywacji ReLU\n",
    "# - dropout ze współczynnikiem odrzucenia 50%\n",
    "# - gęsta z 1 neuronem wyjściowym, funkcja aktywacji sigmoid\n",
    "dropout_model = models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NcVuxWbD-CYr"
   },
   "outputs": [],
   "source": [
    "dropout_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYurnFH7-CYr"
   },
   "outputs": [],
   "source": [
    "#proszę skompilować model, optimizer RMSprop, funkcja kosztu binary crossentropy i śledzoną miarą accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2eyXv1T6pWE"
   },
   "outputs": [],
   "source": [
    "#proszę wytrenować powyższy model, liczba epok: EPOCHS, rozmiar batcha: 512, \n",
    "#proszę podać dane testowe jako validation_data w procesie uczenia\n",
    "dropout_model_hist = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93nQwWzW6pWF"
   },
   "source": [
    "Czas przedstawić wyniki na wykresie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VFHJfm56pWG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dropout_model_val_loss = dropout_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, benchmark_val_loss, 'b+', label='Bazowy model')\n",
    "plt.plot(epochs, dropout_model_val_loss, 'bo', label='Model z regularyzacja dropout')\n",
    "plt.xlabel('Epoki')\n",
    "plt.ylabel('Strata walidacji')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ey854c2h6pWH"
   },
   "source": [
    "\n",
    "Ponownie widać poprawę względem sieci referencyjnej.\n",
    "\n",
    "Reasumując, oto najczęściej stosowane techniki mające zapobiec nadmiernemu dopasowaniu sieci neuronowych:\n",
    "\n",
    "* Zdobycie większej ilości danych treningowych.\n",
    "* Redukcja pojemności sieci.\n",
    "* Dodanie regularyzacji wag.\n",
    "* Dodanie mechanizmu porzucania."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training_NN_continuation-plain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
